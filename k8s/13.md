# Report on lab 13 

## Output of `kubectl get po`

```bash
NAME                   READY   STATUS      RESTARTS       AGE
pod/app-python-0       1/1     Running     0              3m1s
pod/app-python-1       1/1     Running     0              3m1s
pod/vault-0            1/1     Running     5              3m8s
```

## Output of `kubectl get sts`

```bash
NAME                          READY   AGE
statefulset.apps/app-python   2/2     3m1s
statefulset.apps/vault        1/1     3m8s
```

## Output of `kubectl get svc`

```bash
NAME                               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/app-python                 ClusterIP   10.104.127.151   <none>        8000/TCP            3m1s
service/vault                      ClusterIP   10.99.100.131    <none>        8200/TCP,8201/TCP   3m8s
service/vault-agent-injector-svc   ClusterIP   10.104.114.41    <none>        443/TCP             14d
```

## Output of `kubectl get pvc`

```bash
NAME                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/data-app-python-0   Bound    pvc-a4f1263e-1f76-2b47-d83a-6865c52cb3d4   1Gi        RWO            standard       3m1s
persistentvolumeclaim/data-app-python-1   Bound    pvc-74da8342-93dc-4959-b673-a2b5a342da23   1Gi        RWO            standard       3m1s
```

## Visits 

```bash
$ kubectl exec app-python-0 -- cat /app/data/visits.txt
84
$ kubectl exec app-python-1 -- cat /app/data/visits.txt
27
```

The `app-python-0` and `app-python-1` have different numbers of
visits. Kubernetes' load balancing feature does not share the
traffic evenly between pods eve though it speads this network traffic among instances.
`minikube service` sent more requests to the one pod,
and the other pod was probably used for healthchecks. With another
load balancing algorithm the requests could be divided more
evenly between the `app-python-0` and `app-python-1`.

## Guarantees
In our app it is unnecessary to order guarantees because the pods are independent on each other.
So it is okay to run them in parallel.

## Strategy 

`OnDelete`:
one of the strategies for `StatefulSet` by Kubernetes. Lets controller not automatically update the pods.
Only when the pods are deleted by the user, update may be implemented.